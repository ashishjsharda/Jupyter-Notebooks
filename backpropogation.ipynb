{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lj5wv_5Mt6Ph",
        "outputId": "477faa10-6f42-4334-a42e-85429e560f8d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 93ms/step\n",
            "[[0.5008181]\n",
            " [0.5100892]]\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Create a neural network with 1 input layer, 1 hidden layer, and 1 output layer\n",
        "input_layer = tf.keras.layers.Input(shape=(1,))\n",
        "hidden_layer = tf.keras.layers.Dense(4, activation='relu')(input_layer)\n",
        "output_layer = tf.keras.layers.Dense(1, activation='sigmoid')(hidden_layer)\n",
        "model = tf.keras.Model(inputs=input_layer, outputs=output_layer)\n",
        "\n",
        "# Compile the model with binary cross-entropy loss and the Adam optimizer\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam')\n",
        "\n",
        "# Generate some sample training data\n",
        "X = [[0.1], [0.2], [0.3], [0.4]]\n",
        "y = [[0], [0], [1], [1]]\n",
        "\n",
        "# Train the model using backpropagation\n",
        "model.fit(X, y, epochs=1000, verbose=0)\n",
        "\n",
        "# Test the model on some new data\n",
        "test_X = [[0.25], [0.35]]\n",
        "predictions = model.predict(test_X)\n",
        "print(predictions)\n"
      ]
    }
  ]
}